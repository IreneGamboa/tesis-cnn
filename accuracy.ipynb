{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/irene/Documents/Datos-Tesis/Estaciones/SRBA.HHZ.2019-04-09T15:38:36.080000.SAC\n",
      "/home/irene/Documents/Datos-Tesis/Estaciones/HDC3.HHZ.2018-05-10T18:52:34.700000.SAC\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import json\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer, StandardScaler\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from obspy.core import read, UTCDateTime\n",
    "from obspy.io.sac.util import get_sac_reftime\n",
    "from obspy.signal.filter import lowpass, bandpass, highpass\n",
    "import datetime\n",
    "\n",
    "\n",
    "models_file_path = '/home/irene/Documents/Datos-Tesis/models_exp_2.json'\n",
    "sac_files_path = '/home/irene/Documents/Datos-Tesis/Estaciones'\n",
    "cnn_files_path = '/home/irene/Documents/Datos-Tesis/results/exp_2'\n",
    "\n",
    "def rolling_window(a, window, step_size, padding=True, copy=False):\n",
    "    if copy:\n",
    "        result = a.copy()\n",
    "    else:\n",
    "        result = a\n",
    "    if padding:\n",
    "        result = np.hstack((result, np.zeros(window)))\n",
    "    shape = result.shape[:-1] + (result.shape[-1] - window + 1 - step_size, window)\n",
    "    strides = result.strides + (result.strides[-1] * step_size,)\n",
    "    return np.lib.stride_tricks.as_strided(result, shape=shape, strides=strides)\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0))\n",
    "    return (cumsum[N:] - cumsum[:-N]) / float(N)\n",
    "\n",
    "def picker_p_predict(file, scaler, normalizer, cnn, size):\n",
    "    p_is_defined = False\n",
    "    tr = read(file)[0]\n",
    "    if tr.stats.npts >= size:\n",
    "        tr.filter('bandpass', freqmin=1.0, freqmax=10.0, corners=4, zerophase=True)\n",
    "        tr.normalize()\n",
    "\n",
    "        if 'a' in tr.stats.sac and tr.stats.sac.a is not None:\n",
    "            picker_p = int(tr.stats.sac.a * tr.stats.sampling_rate)\n",
    "            p_is_defined = True\n",
    "\n",
    "        if not p_is_defined:\n",
    "            return 1, 1\n",
    "\n",
    "        data = tr.data\n",
    "\n",
    "        #Escalar datos antes de hacer el window\n",
    "        if scaler == 'min_max_scaler':\n",
    "            scaler = MinMaxScaler()\n",
    "        elif scaler == 'standard_scaler':\n",
    "            scaler = StandardScaler()\n",
    "        elif scaler == 'min_max_scaler_1':\n",
    "            scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "        scaler = scaler.fit(tr.data.reshape(-1, 1))\n",
    "        x = scaler.transform(tr.data.reshape(1, -1))[0]\n",
    "        if normalizer:\n",
    "            normalizer = Normalizer().fit(tr.data.reshape(-1, 1))\n",
    "            x = normalizer.transform(x.reshape(1, -1))[0]\n",
    "\n",
    "        input_dataset = rolling_window(x, size, 1)\n",
    "\n",
    "        input_dataset = np.reshape(input_dataset, (len(input_dataset), size, 1))\n",
    "        output = [y[1] for y in cnn.predict(input_dataset)]\n",
    "        output_running_mean = running_mean(output, size)\n",
    "        guess = np.argmax(output_running_mean)\n",
    "\n",
    "        # plt.plot(tr.times(), data)\n",
    "        #\n",
    "        # plt.axvline(x=(guess*tr.stats.delta) , color='green', drawstyle =\"steps-pre\")\n",
    "#         print(\"guess:\", guess)\n",
    "#         print(\"picker_p:\", picker_p)\n",
    "    return guess, picker_p\n",
    "\n",
    "models = json.loads(open(models_file_path).read())\n",
    "ape = {}\n",
    "n = 0\n",
    "\n",
    "for file_name in os.listdir(sac_files_path)[0:15]:\n",
    "    file_name = os.path.join(sac_files_path, file_name)\n",
    "    print(file_name)\n",
    "    # fig = plt.figure(figsize=(15,50))\n",
    "    # fig.subplots_adjust(hspace=2.5, wspace=0.4)\n",
    "    for i, model in enumerate(models):\n",
    "        cnn = load_model(os.path.join(cnn_files_path, '{}.h5'.format(model['name'])))\n",
    "        size = model['input_window_size']\n",
    "        scaler = model['scaler']\n",
    "        normalizer = model['normalizer']\n",
    "        # ax = fig.add_subplot(35, 1, i+1)\n",
    "        # ax.title.set_text('{}'.format(model['name']))\n",
    "        guess, correct = picker_p_predict(file_name, scaler, normalizer, cnn, size)\n",
    "        ape_calc = np.abs(guess - correct)/float(correct)\n",
    "        if model['name'] not in ape:\n",
    "            ape[model['name']] = ape_calc\n",
    "        else:\n",
    "            ape[model['name']] = ape[model['name']] + ape_calc\n",
    "        del cnn\n",
    "    # name = os.path.splitext(os.path.basename(file_name))[0]\n",
    "    # plt.savefig(output_path.format(name))\n",
    "    # plt.close()\n",
    "    n = n + 1\n",
    "\n",
    "for key, value in ape.items():\n",
    "    ape[key] = value/float(n)\n",
    "with open('/home/irene/Documents/Datos-Tesis/ape_result_total.json', 'w') as ape_result:\n",
    "    ape_result.write(json.dumps(ape))\n",
    "print(ape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "obspy",
   "language": "python",
   "name": "obspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
