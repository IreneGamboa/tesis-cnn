{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv1D, Flatten, MaxPooling1D\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "def network(size):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(128, (8,), activation='relu', padding='valid', input_shape=(size, 1)))\n",
    "    model.add(MaxPooling1D((2,), padding='same'))\n",
    "    \n",
    "    model.add(Conv1D(64, (8,), activation='relu', padding='valid'))\n",
    "    model.add(MaxPooling1D((2,), padding='same'))\n",
    "    \n",
    "    model.add(Conv1D(32, (8,), activation='relu', padding='valid'))\n",
    "    model.add(MaxPooling1D((2,), padding='same'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(size, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', 'categorical_accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/irene/Documents/Datos-Tesis/Training/training_data_28\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "size = 60\n",
    "\n",
    "base_path = '/home/irene/Documents/Datos-Tesis/Training'\n",
    "\n",
    "total_files = len(os.listdir(base_path))\n",
    "x_dataset = np.zeros(shape=(0, size))\n",
    "y_dataset = np.zeros(shape=(0, size))\n",
    "\n",
    "for file_path in os.listdir(base_path):\n",
    "    current_index = 0\n",
    "    h5f = h5py.File(os.path.join(base_path, file_path), 'r')\n",
    "    print(\"{}\".format(os.path.join(base_path, file_path)))\n",
    "    while current_index < len(h5f['normal'][:]):\n",
    "        if current_index + size > len(h5f['normal'][:]):\n",
    "            difference = len(h5f['normal'][:]) - current_index\n",
    "            x = h5f['normal'][current_index:current_index+difference]\n",
    "            y = h5f['transformed'][current_index:current_index+difference]\n",
    "            difference2 = size - difference\n",
    "            x = np.append(x, np.zeros(difference2))\n",
    "            y = np.append(y, np.zeros(difference2))\n",
    "        \n",
    "        else:\n",
    "            x = h5f['normal'][current_index:current_index+size]\n",
    "            y = h5f['transformed'][current_index:current_index+size]\n",
    "        if 1 in y:\n",
    "            x_dataset = np.vstack((x_dataset, x))\n",
    "            y_dataset = np.vstack((y_dataset, y))\n",
    "        \n",
    "        current_index = current_index + 1\n",
    "    break\n",
    "\n",
    "x_dataset = np.reshape(x_dataset, (len(x_dataset), size, 1))\n",
    "y_dataset = np.reshape(y_dataset, (len(y_dataset), size))\n",
    "\n",
    "num_to_load = len(x_dataset)\n",
    "split = int(num_to_load * 0.85)\n",
    "\n",
    "x_train = x_dataset[0:split]\n",
    "y_train = y_dataset[0:split]\n",
    "x_test = x_dataset[split:]\n",
    "y_test = y_dataset[split:]\n",
    "    \n",
    "# classifier.save_weights('/home/irene/Documents/Datos-Tesis/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/irene/virtualenvs/obspy/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 0s 8ms/step - loss: 15.8021 - acc: 0.0196 - categorical_accuracy: 0.0196\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 0s 587us/step - loss: 15.8021 - acc: 0.0196 - categorical_accuracy: 0.0196\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 0s 520us/step - loss: 15.8021 - acc: 0.0196 - categorical_accuracy: 0.0196\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 0s 515us/step - loss: 15.8021 - acc: 0.0196 - categorical_accuracy: 0.0196\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 0s 528us/step - loss: 15.8021 - acc: 0.0196 - categorical_accuracy: 0.0196\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 0s 556us/step - loss: 15.8021 - acc: 0.0196 - categorical_accuracy: 0.0196\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 0s 512us/step - loss: 15.8021 - acc: 0.0196 - categorical_accuracy: 0.0196\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 0s 593us/step - loss: 15.8021 - acc: 0.0196 - categorical_accuracy: 0.0196\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 0s 674us/step - loss: 15.8021 - acc: 0.0196 - categorical_accuracy: 0.0196\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 0s 737us/step - loss: 15.8021 - acc: 0.0196 - categorical_accuracy: 0.0196\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 0s 594us/step - loss: 15.8021 - acc: 0.0196 - categorical_accuracy: 0.0196\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 0s 676us/step - loss: 15.8021 - acc: 0.0196 - categorical_accuracy: 0.0196\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 0s 613us/step - loss: 15.8021 - acc: 0.0196 - categorical_accuracy: 0.0196\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 0s 548us/step - loss: 15.8021 - acc: 0.0196 - categorical_accuracy: 0.0196\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 0s 567us/step - loss: 15.8021 - acc: 0.0196 - categorical_accuracy: 0.0196\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 0s 607us/step - loss: 15.8021 - acc: 0.0196 - categorical_accuracy: 0.0196\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 0s 568us/step - loss: 15.8021 - acc: 0.0196 - categorical_accuracy: 0.0196\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 0s 482us/step - loss: 15.8021 - acc: 0.0196 - categorical_accuracy: 0.0196\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 0s 571us/step - loss: 15.8021 - acc: 0.0196 - categorical_accuracy: 0.0196\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 0s 565us/step - loss: 15.8021 - acc: 0.0196 - categorical_accuracy: 0.0196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa47c6ebfd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "classifier = network(size)\n",
    "classifier.fit(x_train, y_train, epochs=20, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 600)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "obspy",
   "language": "python",
   "name": "obspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
